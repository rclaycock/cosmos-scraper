name: Cosmos scrape -> gallery.json

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"   # hourly

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    env:
      URLS: >
        https://www.cosmos.so/rlphoto/swim,
        https://www.cosmos.so/rlphoto/studio-tests,
        https://www.cosmos.so/rlphoto/studio-test-feminine,
        https://www.cosmos.so/rlphoto/swim-resort,
        https://www.cosmos.so/rlphoto/location-tests

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install deps
        run: |
          npm install
          npx playwright install --with-deps chromium

      - name: Scrape all Cosmos pages
        run: |
          IFS=',' read -ra arr <<< "${URLS}"
          mkdir -p public
          for u in "${arr[@]}"; do
            u=$(echo "$u" | xargs)
            slug=$(basename "$u")
            echo "Scraping $u -> public/${slug}.json"
            COSMOS_URL="$u" OUT_FILE="public/${slug}.json" npm run scrape
          done

      - name: Deploy to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages